{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre Processing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKCxHCaaarTK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCKvmkEva5Bd"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# load data\n",
        "d = pd.read_csv('/content/drive/My Drive/Data/training_split.csv')\n",
        "x = d['tweet'].values\n",
        "\n",
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sUq9AhUbC5X"
      },
      "source": [
        "import re\n",
        "\n",
        "# hapus hashtag, mention, link, dan karakter twitter lainnya\n",
        "def filter(string):\n",
        "  string = re.sub(r'@[A-Za-z0-9_]+', '', string)\n",
        "  string = re.sub(r'#[A-Za-z0-9_]+', '', string)\n",
        "  string = re.sub(r'http[A-Za-z0-9_:/?.]+', '', string)\n",
        "  string = string.replace('\\n', '')\n",
        "  string = re.sub(r'\\\\[A-Za-z0-9]+', '', string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4_VNpWWcoh-"
      },
      "source": [
        "# mengubah emoji/ emoticon ke dalam kategori \n",
        "def replace_emoji(string):\n",
        "  kamus = pd.read_excel('/content/drive/My Drive/Data/emoji.csv')\n",
        "  for j in range (len(kamus)):\n",
        "    string = string.replace(kamus['emoji'][j], ' :'+kamus['kategori'][j]+':')\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDW_1PEtf5YH"
      },
      "source": [
        "# mengubah huruf besar menjadi huruf kecil\n",
        "def case_folding(string):\n",
        "  return string.lower().strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZWWfMjSjXn2"
      },
      "source": [
        "# menghapus karakter selain huruf, angka, dan '-'\n",
        "def cleaning(string):\n",
        "  string = re.sub(r'[^a-zA-Z0-9-]', ' ', string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLKJaOLokp3u"
      },
      "source": [
        "# mengubah kata alay ke dalam bentuk formalnya\n",
        "def normalization(string):\n",
        "  tokens = string.split()\n",
        "  kamus = pd.read_csv('/content/drive/My Drive/Data/colloquial-indonesian-lexicon.csv')\n",
        "  text = []\n",
        "  for token in tokens:\n",
        "    for j in range(len(kamus)):\n",
        "      if token == kamus['slang'][j]:\n",
        "        token = token.replace(token, kamus['formal'][j])  \n",
        "    text.append(token)\n",
        "  string = ' '.join(text)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLJra4SumDvs"
      },
      "source": [
        "# hapus angka\n",
        "def cleaning_2(string):\n",
        "  string = re.sub(r'[^a-zA-Z-]', ' ', string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPlsChUwp2jV"
      },
      "source": [
        "!pip install Sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Dxs6VHpZAb"
      },
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "# menghapus stopword\n",
        "def stopword_removal(string):\n",
        "  factory = StopWordRemoverFactory()\n",
        "  stopword = factory.create_stop_word_remover()\n",
        "  string = stopword.remove(string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGiwKUnwqLpy"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# melakukan proses stemming\n",
        "def stemming(string):\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  string = stemmer.stem(string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kugle2EHq6Hg"
      },
      "source": [
        "import json\n",
        "\n",
        "# menyimpan data baru\n",
        "def save(string):\n",
        "  with open('/content/drive/My Drive/prepro.json', 'r') as js:\n",
        "    a = json.load(js)\n",
        "  a.append(string)\n",
        "  with open('/content/drive/My Drive/prepro.json', 'w') as js:\n",
        "    json.dump(a, js)\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWPJP4Jgb1jF"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "for i in range (0, len(x)):\n",
        "  print(i)\n",
        "  string = x [i]\n",
        "  # print(string)\n",
        "  string = filter(string)\n",
        "  # print(string)\n",
        "  string = replace_emoji(string)\n",
        "  # print(string)\n",
        "  string = case_folding(string)\n",
        "  # print(string)\n",
        "  string = cleaning(string)\n",
        "  # print(string)\n",
        "  string = normalization(string)\n",
        "  # print(string)\n",
        "  string = cleaning_2(string)\n",
        "  # print(string)\n",
        "  string = stopword_removal(string)\n",
        "  # print(string)\n",
        "  string = stemming(string)\n",
        "  # print(string)\n",
        "  token = nltk.tokenize.word_tokenize(string)\n",
        "  # print(token)\n",
        "  save(token)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}